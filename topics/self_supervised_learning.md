# Self-Supervised Learning
- [Self-Supervised Learning](#self-supervised-learning)
  - [Generative Adversarial Networks](#generative-adversarial-networks)
  - [Diffusion Model](#diffusion-model)
  - [Autoencoders](#autoencoders)
  - [Visual Prompting](#visual-prompting)
  - [Contrastive Learning](#contrastive-learning)
  - [3D Vision](#3d-vision)
  - [Correspondence](#correspondence)
  - [Vision-Language](#vision-language)
  - [New Paradigms](#new-paradigms)

## Generative Adversarial Networks
- CVPR 2022, [EG3D: Efficient Geometry-aware 3D Generative Adversarial Networks](https://nvlabs.github.io/eg3d/)
- arXiv 2022, [Learning to Learn with Generative Models of Neural Network Checkpoints](https://www.wpeebles.com/Gpt)
- NIPS 2022, [GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images](https://nv-tlabs.github.io/GET3D/)
- CVPR 2021, [Closed-Form Factorization of Latent Semantics in GANs](https://genforce.github.io/sefa/)
- CVPR 2021 oral, VQGAN: [Taming Transformers for High-Resolution Image Synthesis](https://compvis.github.io/taming-transformers/)
- CVPR 2019, StyleGAN: [A Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/abs/1812.04948)

## Diffusion Model
- arXiv 2023, ControlNet: [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)
- ICLR 2023 outstanding paper award, [DreamFusion: Text-to-3D using 2D Diffusion](https://openreview.net/forum?id=FjNys5c7VyY)
- CVPR 2023, [Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models](https://jerryxu.net/ODISE/)
- arXiv 2023, [Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation](https://arxiv.org/abs/2303.07937)
- arXiv 2022, NFD: [3D Neural Field Generation using Triplane Diffusion](https://jryanshue.com/nfd/)
- arXiv 2022, [Point-E: A System for Generating 3D Point Clouds from Complex Prompts](https://arxiv.org/abs/2212.08751)
- NIPS 2022, [LION: Latent Point Diffusion Models for 3D Shape Generation](https://nv-tlabs.github.io/LION/)
- arXiv 2022, 3DiM: [Novel View Synthesis with Diffusion Models](https://3d-diffusion.github.io/)
- CVPR 2022, Stable Diffusion: [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
- NIPS 2021, Guided Diffusion: [Diffusion Models Beat GANS on Image Synthesis](https://arxiv.org/abs/2105.05233)
- NIPS 2020, DDPM: [Denoising Diffusion Probabilistic Models](https://hojonathanho.github.io/diffusion/)


## Autoencoders
- CVPR 2022, [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
- NIPS 2017, VQ-VAE: [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
- NIPS 2016, VGAE: [Variational Graph Auto-Encoders](https://arxiv.org/abs/1611.07308)

## Visual Prompting
-  NIPS 2022, [Visual Prompting via Image Inpainting](https://yossigandelsman.github.io/visual_prompt/)
-  arXiv 2022, [Exploring Visual Prompts for Adapting Large-Scale Models](https://hjbahng.github.io/visual_prompting/)

## Contrastive Learning
- arXiv 2022, [InternVideo: General Video Foundation Models via Generative and Discriminative Learning](https://arxiv.org/abs/2212.03191)
- CVPR 2021, DINO: [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)
- ICML 2021, DeiT: [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
- arXiv 2020, MoCov2: [Improved Baselines with Momentum Contrastive Learning](https://arxiv.org/abs/2003.04297)
- CVPR 2020, MoCo: [Momentum Contrast for Unsupervised Visual Representation Learning](https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)
- NIPS 2020, SwAV: [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882)
- ECCV 2020, [PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding](https://arxiv.org/abs/2007.10985)


## 3D Vision
- NIPS 2022, [CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion](https://croco.europe.naverlabs.com/public/index.html)
- ICCV 2021, [Pri3D: Can 3D Priors Help 2D Representation Learning?](https://arxiv.org/abs/2104.11225)

## Correspondence
- ICLR 2023, [Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild](https://kywind.github.io/self-pose)
- arXiv 2021, [Deep ViT Features as Dense Visual Descriptors](https://dino-vit-features.github.io/)
- ICCV 2021, [The Functional Correspondence Problem](https://agi-labs.github.io/FuncCorr/)
- arXiv 2020, [Keypoints into the future: Self-supervised correspondence in model-based reinforcement learning](https://arxiv.org/abs/2009.05085)
- NIPS 2020, [Space-Time Correspondence as a Contrastive Random Walk](https://ajabri.github.io/videowalk/)
- CVPR 2020, [Self-supervised Learning of Interpretable Keypoints from Unlabelled Videos](https://www.robots.ox.ac.uk/vgg/research/unsupervised_pose/)
- CVPR 2019, [Learning Correspondence from the Cycle-Consistency of Time](https://ajabri.github.io/timecycle/)
- NIPS 2018, [Unsupervised Learning of Object Landmarks through Conditional Image Generation](https://www.robots.ox.ac.uk/~vgg/research/unsupervised_landmarks/)
- ECCV 2018, [Videos as Space-Time Region Graphs](https://arxiv.org/abs/1806.01810v2)

## Vision-Language
- arXiv 2022, [PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning](https://arxiv.org/abs/2211.11682)
- CVPR 2022, [PointCLIP: Point Cloud Understanding by CLIP](https://arxiv.org/abs/2112.02413)
- ICML 2021, CLIP: [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- NIPS 2022, [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)

## New Paradigms
- NIPS 2022, [Visual Pre-training for Navigation: What Can We Learn from Noise?](https://yanweiw.github.io/noise2ptz/)
- NIPS 2021, [MarioNette: Self-Supervised Sprite Learning](https://people.csail.mit.edu/smirnov/marionette/)
- NIPS 2020, [Object-Centric Learning with Slot Attention](https://arxiv.org/abs/2006.15055)
